{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad CAM을 이용한 딥러닝 모형 해석\n",
    "- http://freesearch.pe.kr/archives/4685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_csv(\"ratings_train.txt\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
       "6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
       "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
       "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
       "9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [mecab.morphs(str(i).strip()) for i in tbl['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "keywords = [word for word in keywords if word not in stopwords.words('korean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 150000, (150000, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(k) for k in keywords]), len(keywords), tbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_cnt = Counter([i for item in keywords for i in item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#간단하게 진행하기 위해 가장 빈도수가 많은 상위 5000개의 키워드만 사용한다. \n",
    "keyword_clip = sorted(keyword_cnt.items(), key=operator.itemgetter(1))[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_clip_dict = dict(keyword_clip)\n",
    "keyword_dict = dict(zip(keyword_clip_dict.keys(), range(len(keyword_clip_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공백과 미학습 단어 처리를 위한 사전 정보 추가  \n",
    "keyword_dict['_PAD_'] = len(keyword_dict)\n",
    "keyword_dict['_UNK_'] = len(keyword_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드를 역추적하기 위한 사전 생성 \n",
    "keyword_rev_dict = dict([(v,k) for k, v in keyword_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 시퀀스 단어수의 중앙값 +5를 max 리뷰 시퀀스로 정함... \n",
    "max_seq =np.median([len(k) for k in keywords]) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_and_padding(corp_list, dic, max_seq=50):\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    coding_seq = [ [dic.get(j, dic['_UNK_']) for j in i]  for i in corp_list ]\n",
    "    #일반적으로 리뷰는 마지막 부분에 많은 정보를 포함할 가능성이 많아 패딩은 앞에 준다. \n",
    "    return(pad_sequences(coding_seq, maxlen=max_seq, padding='pre', truncating='pre',value=dic['_PAD_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "train_x = encoding_and_padding(keywords, keyword_dict, max_seq=int(max_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tbl['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 19), (150000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(train_x.shape[1],), name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "embeddings_out = Embedding(input_dim=len(keyword_dict) , output_dim=50,name='embedding')(inputs)\n",
    "\n",
    "conv0 = Conv1D(32, 1, padding='same')(embeddings_out)\n",
    "conv1 = Conv1D(16, 2, padding='same')(embeddings_out)\n",
    "conv2 = Conv1D(8, 3, padding='same')(embeddings_out)\n",
    "\n",
    "pool0 = AveragePooling1D()(conv0)\n",
    "pool1 = AveragePooling1D()(conv1)\n",
    "pool2 = AveragePooling1D()(conv2)\n",
    "\n",
    "concat_layer = concatenate([pool0, pool1, pool2],axis=2)\n",
    "\n",
    "bidir =Bidirectional(GRU(10, recurrent_dropout=0.2, dropout=0.2))(concat_layer)\n",
    "\n",
    "out = Dense(1,activation='sigmoid')(bidir)\n",
    "\n",
    "model = Model(inputs=[inputs,], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 19)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 19, 50)       250100      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 19, 32)       1632        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 19, 16)       1616        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 19, 8)        1208        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 9, 32)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_2 (AveragePoo (None, 9, 16)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_3 (AveragePoo (None, 9, 8)         0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9, 56)        0           average_pooling1d_1[0][0]        \n",
      "                                                                 average_pooling1d_2[0][0]        \n",
      "                                                                 average_pooling1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 20)           4020        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            21          bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 258,597\n",
      "Trainable params: 258,597\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "135000/135000 [==============================] - 29s 212us/step - loss: 0.4098 - val_loss: 0.3666\n",
      "Epoch 2/10\n",
      "135000/135000 [==============================] - 26s 195us/step - loss: 0.3537 - val_loss: 0.3443\n",
      "Epoch 3/10\n",
      "135000/135000 [==============================] - 26s 195us/step - loss: 0.3344 - val_loss: 0.3394\n",
      "Epoch 4/10\n",
      "135000/135000 [==============================] - 26s 194us/step - loss: 0.3232 - val_loss: 0.3333\n",
      "Epoch 5/10\n",
      "135000/135000 [==============================] - 27s 197us/step - loss: 0.3145 - val_loss: 0.3316\n",
      "Epoch 6/10\n",
      "135000/135000 [==============================] - 27s 203us/step - loss: 0.3067 - val_loss: 0.3356\n",
      "Epoch 7/10\n",
      " 38300/135000 [=======>......................] - ETA: 18s - loss: 0.3000"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "hist = model.fit(x=train_x,y=train_y, batch_size=100, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_test = pd.read_csv(\"ratings_test.txt\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_text = [mecab.morphs(str(i).strip()) for i in tbl_test['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = encoding_and_padding(parsed_text, keyword_dict, max_seq=int(max_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = tbl_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_conv1D(model, layer_nm, x, sample_weight=1,  keras_phase=0):\n",
    "    import keras.backend as K\n",
    "    import numpy as np\n",
    "    \n",
    "    #레이어 이름에 해당되는 레이어 정보를 가져옴 \n",
    "    layers_wt = model.get_layer(layer_nm).weights\n",
    "    layers = model.get_layer(layer_nm)\n",
    "    layers_weights = model.get_layer(layer_nm).get_weights()\n",
    "    \n",
    "    #긍정 클래스를 설명할 수 있게 컨볼루션 필터 가중치의 gradient를 구함  \n",
    "    grads = K.gradients(model.output[:,0], layers_wt)[0]\n",
    "    \n",
    "    #필터별로 가중치를 구함 \n",
    "    pooled_grads = K.mean(grads, axis=(0,1))\n",
    "    get_pooled_grads = K.function([model.input,model.sample_weights[0], K.learning_phase()], \n",
    "                         [pooled_grads, layers.output[0]])\n",
    "    \n",
    "    pooled_grads_value, conv_layer_output_value = get_pooled_grads([[x,], [sample_weight,], keras_phase])\n",
    "    #다시한번 이야기 하지만 loss를 줄이기 위한 학습과정이 아니다... \n",
    "    for i in range(conv_layer_output_value.shape[-1]):\n",
    "        conv_layer_output_value[:, i] *= pooled_grads_value[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    return((heatmap, pooled_grads_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋에서 90번째 인덱스에 해당하는 데이터를 시각화 해본다. \n",
    "idx = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[idx], tbl_test.iloc[idx], test_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm, graded = grad_cam_conv1D(model, 'conv1d_1', x=test_x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_tbl = pd.DataFrame({'heat':hm, 'kw':[keyword_rev_dict[i] for i in test_x[idx] ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hm_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
